{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_16_04.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 16.04: Guided Exercise**\n",
        "###  Modeling and predictions using ML pipelines"
      ],
      "metadata": {
        "id": "bjC052XoyKus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing modules"
      ],
      "metadata": {
        "id": "zwrcvUXyycPq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHkHVZAlInQn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data"
      ],
      "metadata": {
        "id": "R4cOuXMGygI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'https://raw.githubusercontent.com/OsamaAkhlaq/DS_Book/main/Chapter%2016/pima-indians-diabetes.csv'\n",
        "# Loading the data using pandas\n",
        "\n",
        "diabData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
        "diabData.head()"
      ],
      "metadata": {
        "id": "JNpUa4gEI2nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding number of null values in the data set"
      ],
      "metadata": {
        "id": "YhuODiokykSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "diabData.isnull().sum()"
      ],
      "metadata": {
        "id": "Ov4v5bjZLklM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping all the rows with na values"
      ],
      "metadata": {
        "id": "bbCOJ_2UynUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newdiabdata = diabData.dropna(axis = 0)"
      ],
      "metadata": {
        "id": "CnuBp4dHLnHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing the shape of earlier data set and new data set"
      ],
      "metadata": {
        "id": "YvyRggL8ypZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(diabData.shape)\n",
        "print(newdiabdata.shape)"
      ],
      "metadata": {
        "id": "qIEv91pYOT4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seperating X and y variables"
      ],
      "metadata": {
        "id": "z_NJDEWRyse8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = newdiabdata.loc[:,0:8]\n",
        "print(X.shape)\n",
        "y = newdiabdata.loc[:,8]\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "0OQJq2KoLqVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the data into train and test sets"
      ],
      "metadata": {
        "id": "L7DIftn6yvJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "sYTQey-PLvKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipe line for Dummy creation\n"
      ],
      "metadata": {
        "id": "f6xqtDNUPAPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importing the necessary packages\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "eXZ62Js3O-YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "# Pipeline for transforming categorical variables\n",
        "catTransformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "# Pipeline for scaling numerical variables\n",
        "numTransformer = Pipeline(steps=[('scaler', StandardScaler())])"
      ],
      "metadata": {
        "id": "GMZ4ihXyPD0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing dtypes for X"
      ],
      "metadata": {
        "id": "0mZFHdlDyzdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X.dtypes"
      ],
      "metadata": {
        "id": "DLZzB6gePHoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting numerical features"
      ],
      "metadata": {
        "id": "JdYNBKhwy2C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "numFeatures = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "numFeatures"
      ],
      "metadata": {
        "id": "AtYkszFDPigl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting Categorical features"
      ],
      "metadata": {
        "id": "YTy5bxkly4uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catFeatures = X.select_dtypes(include=['object']).columns\n",
        "catFeatures"
      ],
      "metadata": {
        "id": "tjpPlyqyPjTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the preprocessing engine"
      ],
      "metadata": {
        "id": "tUVFcfEwy7it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric', numTransformer, numFeatures),\n",
        "        ('categoric', catTransformer, catFeatures)])"
      ],
      "metadata": {
        "id": "PJUVTmLrPn7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming the Training data"
      ],
      "metadata": {
        "id": "Sv1GFJT_y91x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtran_train = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
        "print(Xtran_train.shape)\n",
        "Xtran_train.head()"
      ],
      "metadata": {
        "id": "oRGcOjkIPqCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming Test data"
      ],
      "metadata": {
        "id": "GIaoRJuEzBby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtran_test = pd.DataFrame(preprocessor.transform(X_test))\n",
        "print(Xtran_test.shape)\n",
        "Xtran_test.head()"
      ],
      "metadata": {
        "id": "-tGkJ7H3Pssg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dimensionality reduction after processing with Pipeline"
      ],
      "metadata": {
        "id": "WODS6H96Q7hO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing PCA library\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "c-38CdKhQ5XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an estimator with both preprocessor and dimensionality reduction"
      ],
      "metadata": {
        "id": "fbrFC0AhzFIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('dimred', PCA(5)),\n",
        "                      ('clf',LogisticRegression(random_state=123))])"
      ],
      "metadata": {
        "id": "s4MPjWKSQ9_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "AwfL4mJgfMDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the score on the test set"
      ],
      "metadata": {
        "id": "xG3i_AGkzIOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "estimator.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "OTb2z-JbfXCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the predictions on test set"
      ],
      "metadata": {
        "id": "SY2rKmHYzKpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred = estimator.predict(X_test)"
      ],
      "metadata": {
        "id": "C1BjqAYPfsSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing the classification report"
      ],
      "metadata": {
        "id": "maimAt-HzNe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(pred,y_test))"
      ],
      "metadata": {
        "id": "yim2MEwIft9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating confusion matrix"
      ],
      "metadata": {
        "id": "O_lzOLfCzRAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusionMatrix = confusion_matrix(y_test, pred)\n",
        "print(confusionMatrix)"
      ],
      "metadata": {
        "id": "9b9VfU7JfyYD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}