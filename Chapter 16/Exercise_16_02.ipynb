{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_16_02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 16.02: Guided Exercise**\n",
        "### Applying pipelines for Feature Extraction to the Dataset:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BerfVxYFplUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Modules"
      ],
      "metadata": {
        "id": "2-bKJYikq4Y6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHkHVZAlInQn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data"
      ],
      "metadata": {
        "id": "cBXN2YUUq8g8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'https://raw.githubusercontent.com/OsamaAkhlaq/DS_Book/main/Chapter%2016/pima-indians-diabetes.csv'\n",
        "# Loading the data using pandas\n",
        "\n",
        "notesData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
        "notesData.head()"
      ],
      "metadata": {
        "id": "JNpUa4gEI2nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding number of null values in the data set"
      ],
      "metadata": {
        "id": "vFLieRxZrERS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notesData.isnull().sum()"
      ],
      "metadata": {
        "id": "Ov4v5bjZLklM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping all the rows with na values"
      ],
      "metadata": {
        "id": "VqU4XzSwrG_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newnotesdata = notesData.dropna(axis = 0)"
      ],
      "metadata": {
        "id": "CnuBp4dHLnHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing the shape of earlier data set and new data set"
      ],
      "metadata": {
        "id": "vYkR25-GrKY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(notesData.shape)\n",
        "print(newnotesdata.shape)"
      ],
      "metadata": {
        "id": "qIEv91pYOT4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperating X and y variables\n",
        "X = newnotesdata.loc[:,0:3]\n",
        "print(X.shape)\n",
        "y = newnotesdata.loc[:,4]\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "0OQJq2KoLqVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the data into train and test sets"
      ],
      "metadata": {
        "id": "GXoHvJm-rSen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "sYTQey-PLvKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipe line for Dummy creation\n"
      ],
      "metadata": {
        "id": "f6xqtDNUPAPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary packages\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "eXZ62Js3O-YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "# Pipeline for transforming categorical variables\n",
        "catTransformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "# Pipeline for scaling numerical variables\n",
        "numTransformer = Pipeline(steps=[('scaler', StandardScaler())])"
      ],
      "metadata": {
        "id": "GMZ4ihXyPD0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing dtypes for X"
      ],
      "metadata": {
        "id": "De-kTKpnrY_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.dtypes"
      ],
      "metadata": {
        "id": "DLZzB6gePHoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting numerical features"
      ],
      "metadata": {
        "id": "pMAMkv64rcFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numFeatures = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "numFeatures"
      ],
      "metadata": {
        "id": "AtYkszFDPigl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting Categorical features"
      ],
      "metadata": {
        "id": "o3TW15CRrgxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "catFeatures = X.select_dtypes(include=['object']).columns\n",
        "catFeatures"
      ],
      "metadata": {
        "id": "tjpPlyqyPjTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the preprocessing engine"
      ],
      "metadata": {
        "id": "o9TS0k-irj1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric', numTransformer, numFeatures),\n",
        "        ('categoric', catTransformer, catFeatures)])"
      ],
      "metadata": {
        "id": "PJUVTmLrPn7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming the Training data"
      ],
      "metadata": {
        "id": "Vr_3S1q5rnhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtran_train = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
        "print(Xtran_train.shape)\n",
        "Xtran_train.head()"
      ],
      "metadata": {
        "id": "oRGcOjkIPqCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming Test data"
      ],
      "metadata": {
        "id": "bVR7xJkHrsPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtran_test = pd.DataFrame(preprocessor.transform(X_test))\n",
        "print(Xtran_test.shape)\n",
        "Xtran_test.head()"
      ],
      "metadata": {
        "id": "-tGkJ7H3Pssg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}